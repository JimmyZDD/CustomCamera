//
//  MyMovieWithAssetWriterController.m
//  CustomMyCameraDemo01
//
//  Created by TuSDK on 16/7/1.
//  Copyright Â© 2016å¹´ TuSDK. All rights reserved.
//



#import "MyMovieWithAssetWriterController.h"
#import <AVFoundation/AVFoundation.h>
#import "MPMoviePlayController.h"

#define kMainScreenWidth [UIScreen mainScreen].bounds.size.width
#define kMainScreenHeight  [UIScreen mainScreen].bounds.size.height
/**
 *  å®ä¸€ä¸ªç®€å•çš„è­¦å‘Šæ¡†
 *
 *  @param title æç¤ºå†…å®¹
 *
 *  @return nil
 */
#define ShowAlert(...) [[[UIAlertView alloc] initWithTitle:@"æç¤º" message:__VA_ARGS__ delegate:nil cancelButtonTitle:@"ç¡®å®š" otherButtonTitles:nil, nil] show]
// è‡ªå®šä¹‰Logä¿¡æ¯
#ifdef DEBUG
#define LOG(...) NSLog(__VA_ARGS__);
#define LOG_METHOD NSLog(@"%s", __func__);
#else
#define LOG(...);
#define LOG_METHOD;
#endif


static CGFloat DegreesToRadians(CGFloat degrees) {return degrees * M_PI / 180;};//å¼§åº¦è§’åº¦è½¬æ¢

@interface MyMovieWithAssetWriterController ()<AVCaptureVideoDataOutputSampleBufferDelegate>

/**
 *  æ˜¯å¦å¼€å§‹å½•åˆ¶
 */
@property (nonatomic, assign) BOOL started;
/**
 *  ä¸»è¦ç”¨åœ¨è§†é¢‘æ–¹é¢  CMTime å¸§ å’Œ æ—¶é—´ å°ˆé–€ç”¨ä¾†è¡¨ç¤ºå½±ç‰‡æ™‚é–“ç”¨çš„é¡åˆ¥
 CMTimeMake(a,b)    aå½“å‰ç¬¬å‡ å¸§, bæ¯ç§’é’Ÿå¤šå°‘å¸§.å½“å‰æ’­æ”¾æ—¶é—´a/b
 
 CMTimeMakeWithSeconds(a,b)    aå½“å‰æ—¶é—´,bæ¯ç§’é’Ÿå¤šå°‘å¸§.
 */
@property (nonatomic, assign) CMTime frameDuration;
/**
 *  ä¸‹ä¸€ä¸ªä¼ è¾“
 Rational time value represented as int64/int32.
 */
@property (nonatomic, assign) CMTime nextPTS;
/**
 *  æ•è·è®¾å¤‡ä¼šè¯å±‚
 */
@property (nonatomic, retain) AVCaptureSession* captureSession;

/**
 *  AVAssetWriterå†™å…¥åª’ä½“æ•°æ®åˆ°ä¸€ä¸ªæ–°çš„æ–‡ä»¶æä¾›çš„æœåŠ¡ï¼Œ
 */
@property (nonatomic, retain) AVAssetWriter *assetWriter;

/**
 *  é™„åŠ åª’ä½“æ ·æœ¬åŒ…è£…ä¸ºCMSamplebufferå¯¹è±¡
 */
@property (nonatomic, retain) AVAssetWriterInput *assetWriterInput;

/**
 *  è§†é¢‘æ•°æ®è¾“å‡º
 */
@property (nonatomic, retain) AVCaptureVideoDataOutput* videoOutput;

/**
 *  æ‰“å¼€ Mov é“¾æ¥
 */
@property (nonatomic, retain) NSURL *outputMovURL;

/**
 *  æ‰“å¼€ Mp4 é“¾æ¥
 */
@property (nonatomic, retain) NSURL* outputMp4URL;
/**
 *  è¿›åº¦æ¡
 */
@property (nonatomic, retain) UIProgressView* progressBar;

/**
 *  é¢„è§ˆå±‚ä¿¯è§†å›¾
 */
@property (weak, nonatomic) IBOutlet UIView *preview;

/**
 *  è§†é¢‘å½“å‰å¸§
 */

@property (nonatomic, assign) NSInteger currentFrame;
/**
 *  è§†é¢‘æœ€å¤§å¸§æ•°
 */
@property (nonatomic, assign) NSInteger maxFrame;


@property (weak, nonatomic) IBOutlet UIToolbar *topBar;

@end

@implementation MyMovieWithAssetWriterController
#pragma mark - capture method
- (void)setupAVCapture {
    NSError *error = nil;
    self.captureSession = [AVCaptureSession new];
    // è®¾ç½®åˆ†è¾¨ç‡
    if ([_captureSession canSetSessionPreset:AVCaptureSessionPreset640x480]) {
        [_captureSession setSessionPreset:AVCaptureSessionPreset640x480];
    }
    // ä¸ºä¼šè¯å±‚æ·»åŠ è¾“å…¥è®¾å¤‡
    AVCaptureDevice *backCamera = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];
    LOG(@"backCamera.position:%d",backCamera.position);
    AVCaptureDeviceInput *captureDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:backCamera error:&error];
    if (error) {
        ShowAlert(@"åˆå§‹åŒ–ç›¸æœºå‡ºé”™");
        return;
    }
    if ([_captureSession canAddInput:captureDeviceInput]) {
        [_captureSession addInput:captureDeviceInput];
    }
    
    // ä¸ºä¼šè¯å±‚æ·»åŠ è¾“å‡ºè®¾å¤‡
    self.videoOutput = [AVCaptureVideoDataOutput new];
    // ä¸¢å¼ƒæœ€åä¸€å¸§
    [_videoOutput setAlwaysDiscardsLateVideoFrames:YES];
    if ([_captureSession canAddOutput:_videoOutput]) {
        [_captureSession addOutput:_videoOutput];
    }
    
    // åˆ›å»ºä¸€ä¸ªä¸²è¡Œé˜Ÿåˆ— æ¥å¤„ç†è¾“å‡ºè®¾å¤‡çš„å›è°ƒäº‹ä»¶
    dispatch_queue_t queue = dispatch_queue_create("myQueue", NULL);
    [_videoOutput setSampleBufferDelegate:self queue:queue];
    // dispatch_release(queue);// æ‰‹åŠ¨é‡Šæ”¾ åœ¨ARCä¸‹GCDé˜Ÿåˆ—è‡ªåŠ¨é‡Šæ”¾
    _videoOutput.videoSettings = @{
            (id)kCVPixelBufferPixelFormatTypeKey:[NSNumber numberWithInt:kCVPixelFormatType_32BGRA]
#pragma mark -- è¿™ä¸ªæ­Œæ˜¯ä»€ä¹ˆ
            // åˆ†è¾¨ç‡ç¼“å­˜ åˆ†è¾¨ç‡æ ¼å¼åŒ–Key   åˆå§‹åŒ–æ‘„åƒå¤´çš„æ—¶å€™ï¼Œè®¾ç½®é‡‡é›†æ ¼å¼æ˜¯32bit rgbçš„
                                   };
    // åˆå§‹åŒ–è§†å±é¢„è§ˆå±‚
    AVCaptureVideoPreviewLayer *previewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:_captureSession];
    [previewLayer setVideoGravity:AVLayerVideoGravityResizeAspectFill];
    [previewLayer setFrame:[_preview bounds]];
    _preview.layer.masksToBounds = YES;
    [_preview.layer addSublayer:previewLayer];
}
/**
 *  åˆå§‹åŒ–ä¸€ä¸ªæ–‡ä»¶å†™å…¥ç±»
 *
 *  @param fileURL              æ–‡ä»¶è·¯å¾„
 *  @param formatDescriptionRef å¼•ç”¨ä¸€ä¸ªCMFormatDescriptionï¼Œæè¿°çš„ç‰¹å®šç±»å‹ï¼ˆéŸ³é¢‘ï¼Œè§†é¢‘ï¼Œæ··åˆéŸ³è§†é¢‘ç­‰ç­‰ï¼‰çš„åª’ä½“çš„CFå¯¹è±¡ã€‚
 */
- (BOOL)setupAssetWriterForURL:(NSURL *)fileURL formatDescription:(CMFormatDescriptionRef)formatDescriptionRef {
    NSError *error = nil;
    
    // allocate the writer object with our output file URL
    // ä½¿ç”¨è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„åˆå§‹åŒ–å†™å¯¹è±¡
    self.assetWriter = [[AVAssetWriter alloc]initWithURL:fileURL fileType:AVFileTypeQuickTimeMovie error:&error];
    if (error) {
        ShowAlert(@"åˆå§‹åŒ–assetWriterå¯¹è±¡å‡ºé”™");
        return NO;
    }
    
    // initialized a new input for video to receive sample buffers for writing
    // åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„è¾“å…¥è®¾å¤‡æ¥æ¥æ”¶åŸæ ·æ•°æ®ç”¨æ¥å†™å…¥
    // passing nil for outputSettings instructs the input to pass through appended samples, doing no processing before they are written
    // é€šè¿‡è®¾ç½®outputSettingsä¸ºç©ºæŒ‡ç¤º ä¼ é€’é€šè¿‡é™„åŠ æ ·æœ¬,ä¸åšä»»ä½•å¦‚ç†åœ¨å†™å…¥ä¹‹å‰
    // ä¸‹é¢è¿™ä¸ªå‚æ•°ï¼Œè®¾ç½®å›¾åƒè´¨é‡ï¼Œæ•°å­—è¶Šå¤§ï¼Œè´¨é‡è¶Šå¥½
#pragma mark -- è®¾ç½®ä¸€äº›è¾“å‡ºçš„å‚æ•°
    /**
     *  è®¾ç½®å¹³å‡æ¯”ç‰¹ç‡
     */
    NSDictionary *videoCompressionProps =
    @{
      AVVideoAverageBitRateKey:[NSNumber numberWithDouble:512*1024.0]
      // å¹³å‡æ¯”ç‰¹ç‡
     };
    // è®¾ç½®ç¼–ç å’Œå®½é«˜æ¯”ã€‚å®½é«˜æ¯”æœ€å¥½å’Œæ‘„åƒæ¯”ä¾‹ä¸€è‡´ï¼Œå¦åˆ™å›¾ç‰‡å¯èƒ½è¢«å‹ç¼©æˆ–æ‹‰ä¼¸ å‹ç¼©å±æ€§
    NSDictionary *outputSettingsDic =
    @{
      AVVideoCodecKey:AVVideoCodecH264,
      // ç¼–è§£ç å™¨
      AVVideoWidthKey:[NSNumber numberWithFloat:320.0f],
      AVVideoHeightKey:[NSNumber numberWithFloat:240.0f],
      AVVideoCompressionPropertiesKey:videoCompressionProps
      // è§†é¢‘å‹ç¼©å±æ€§
      };
    // åˆå§‹åŒ–æ–‡ä»¶å†™å…¥å…¥å£
    self.assetWriterInput = [AVAssetWriterInput assetWriterInputWithMediaType:AVMediaTypeVideo outputSettings:outputSettingsDic];
    
    // æŒ‡ç¤º  è¾“å…¥æ˜¯å¦åº”è¯¥è°ƒæ•´(é€‚åº”)å…¶(å®æ—¶æº)çš„åª’ä½“æ•°æ®å¤„ç†ã€‚
    // Indicates whether the input should tailor its processing of media data for real-time sources.
    [_assetWriterInput setExpectsMediaDataInRealTime:YES];
    
    // è®¾ç½®å†™å…¥è§†é¢‘æ–‡ä»¶æ—‹è½¬è§’åº¦
    CGFloat rotationRadians = [self getRotationRadiansForAssetWriterInput];
    [self.assetWriterInput setTransform:CGAffineTransformMakeRotation(rotationRadians)];
#pragma mark -- ä¸ºæ–‡ä»¶å†™å…¥ç±»æ·»åŠ ä¸€ä¸ªè¾“å…¥æº
    // ä¸ºæ–‡ä»¶å†™å…¥ç±»æ·»åŠ ä¸€ä¸ªè¾“å…¥æº
    if ([self.assetWriter canAddInput:self.assetWriterInput]) {
        [self.assetWriter addInput:self.assetWriterInput];
    }
    
    

#pragma mark -- åœ¨æ—¶é—´0å¼€å§‹ä¸€ä¸ªé‡‡æ ·å†™å…¥
    // initiates a sample-writing at time 0
    // åœ¨æ—¶é—´0å¼€å§‹ä¸€ä¸ªé‡‡æ ·å†™å…¥
    self.nextPTS = kCMTimeZero;
    [self.assetWriter startWriting];
    [self.assetWriter startSessionAtSourceTime:self.nextPTS];
    
    return YES;
}
/**
 *  æ ¹æ®è®¾å¤‡æ–¹å‘è¿”å›å†™å…¥è§†é¢‘æ–‡ä»¶æ—‹è½¬å¼§åº¦
 *
 *  @return æ—‹è½¬å¼§åº¦
 */
- (CGFloat)getRotationRadiansForAssetWriterInput {
    CGFloat rotationDegrees;// æ—‹è½¬ç³»æ•°
    switch ([[UIDevice currentDevice] orientation]) {
        case UIDeviceOrientationPortraitUpsideDown:
            rotationDegrees = -90.;
            break;
        case UIDeviceOrientationLandscapeLeft: // no rotation
            rotationDegrees = 0.;
            break;
        case UIDeviceOrientationLandscapeRight:
            rotationDegrees = 180.;
            break;
        case UIDeviceOrientationPortrait:
        case UIDeviceOrientationUnknown:
        case UIDeviceOrientationFaceUp:
        case UIDeviceOrientationFaceDown:
        default:
            rotationDegrees = 90.;
            break;
    }
    CGFloat rotationRadians = DegreesToRadians(rotationDegrees);
    return rotationRadians;
}
#pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate

/**
 *  Called whenever an AVCaptureVideoDataOutput instance outputs a new video frame.
 *  æ¯å½“AVCaptureVideoDataOutputå®ä¾‹è¾“å‡ºä¸€ä¸ªæ–°çš„è§†é¢‘å¸§è°ƒç”¨ã€‚
 *
 */
// Delegate routine that is called when a sample buffer was written æ¯ç§’é’Ÿè°ƒç”¨30æ¬¡ï¼Ÿ
- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection
{
    LOG(@"AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿");
    if (self.started) {
        // set up the AVAssetWriter using the format description from the first sample buffer captured
#pragma mark -- ä½¿ç”¨æ ¼å¼æè¿°ä»æ‹æ‘„çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ç¼“å†²åŒº å»ºç«‹AVAssetWriter
        if ( self.assetWriter == nil ) {
            CMFormatDescriptionRef formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer);
         // ä¸åœ¨æˆåŠŸç›´æ¥æˆåŠŸreturn
            if (![self setupAssetWriterForURL:_outputMovURL formatDescription:formatDescription]) {
                LOG(@"setupAssetWriterForURL error");
                return;
            }
        }
        // re-time the sample buffer - in this sample frameDuration is set to 5 fps
        // åŸæ ·æ•°æ® æ—¶åºä¿¡æ¯
        /**
         *  åœ¨ä¸€ä¸ªCMSampleBufferæ ·æœ¬æ—¶åºä¿¡æ¯çš„æ”¶é›†ã€‚
         *  å•CMSampleTimingInfoç»“æ„å¯ä»¥æè¿°æ¯ä¸€ä¸ªä¸ªä½“æ ·å“ä¸­çš„CMSampleBufferï¼Œå¦‚æœæ ·å“éƒ½å…·æœ‰ç›¸åŒçš„æŒç»­æ—¶é—´å’Œæ˜¯åœ¨æ²¡æœ‰é—´éš™å‘ˆç°é¡ºåºã€‚
         */
        CMSampleTimingInfo timingInfo = kCMTimingInfoInvalid;// é¦–å…ˆæŒ‡å‘ä¸€ä¸ªç©ºçš„å¯¹è±¡
        /**
         *  å½“å‰æ—¶é—´
         *  æ ·æœ¬çš„æŒç»­æ—¶é—´ã€‚
         *  å¦‚æœå•ä¸€ç»“æ„é€‚ç”¨äºæ¯ä¸ªæ ·å“æ—¶ï¼Œéƒ½å°†æœ‰æ­¤æŒç»­æ—¶é—´ã€‚
         */
        timingInfo.duration = self.frameDuration;// æŒç»­æ—¶é—´
        /**
         *  å‘ˆç°ï¼ˆå½“å‰ï¼‰æ—¶é—´æˆ³
         *  åœ¨å…¶ä¸­æ ·å“å°†è¢«å‘ˆç°çš„æ—¶é—´ã€‚
         *  å¦‚æœå•ç»“æ„é€‚ç”¨äºå„æ ·å“ï¼Œè¿™æ˜¯å…¶ä¸­çš„presentationTimeç¬¬ä¸€ä¸ªæ ·æœ¬ã€‚
         *  åç»­æ ·å“çš„presentationTimeå°†ç”±è¡ç”Ÿåå¤æ·»åŠ æ ·å“çš„æŒç»­æ—¶é—´ã€‚
         */
        timingInfo.presentationTimeStamp = self.nextPTS; // å‘ˆç°ï¼ˆå½“å‰ï¼‰æ—¶é—´æˆ³
        
        /**
         *  ä¸²è¡Œæ•°æ®ç¼“å­˜å™¨
         *  ä¸€ä¸ªCMSampleBufferçš„å¼•ç”¨ï¼ŒåŒ…å«CFå¯¹è±¡çš„å¼•ç”¨é›¶ä¸ªæˆ–å¤šä¸ªå‹ç¼©ï¼ˆæˆ–å‹ç¼©ï¼‰ç‰¹å®šçš„åª’ä½“ç±»å‹ï¼ˆéŸ³é¢‘ï¼Œè§†é¢‘ï¼Œå¤šå·¥ç­‰ï¼‰çš„æ ·å“ã€‚
         */
        CMSampleBufferRef sbufWithNewTiming = NULL;
        /**
         *  åˆ›å»ºå‰¯æœ¬CMSampleBufferæ–°çš„è®¡æ—¶ä¿¡æ¯ã€‚
         *
         *  @param kCFAllocatorDefault åˆ†é…å™¨ç”¨äºåˆ†é…CMSampleBufferå¯¹è±¡ã€‚
                                       é€šè¿‡kCFAllocatorDefaultä½¿ç”¨é»˜è®¤åˆ†é…å™¨ã€‚
         *  @param sampleBuffer        CMSampleBufferåŒ…å«åŸå§‹æ ·æœ¬ã€‚
         *  @param 1                   åœ¨æ¡ç›®æ•°sampleTimingArrayã€‚
                                       å¿…é¡»åœ¨åŸsampleBufferæ˜¯0ï¼Œ1æˆ–NUMSAMPLES
         *  @param timingInfo          æ•°ç»„CMSampleTimingInfoç»“æ„ï¼Œæ¯é‡‡æ ·1ç»“æ„ã€‚
                                       å¦‚æœæ‰€æœ‰çš„æ ·å“éƒ½å…·æœ‰ç›¸åŒçš„æŒç»­æ—¶é—´ï¼Œå¹¶ä¸”åœ¨å‘ˆç°é¡ºåºï¼Œ
                                       åˆ™å¯ä»¥é€šè¿‡ä¸€ä¸ªå•ä¸€ CMSampleTimingInfoç»“æ„ä¸æŒç»­æ—¶é—´è®¾ç½®ä¸ºä¸€ä¸ªæ ·æœ¬çš„æŒç»­æ—¶é—´presentationTimeStamp è®¾ç½®ä¸ºæ•°å€¼æœ€æ—©æ ·å“çš„æ˜¾ç°æ—¶é—´ï¼Œå¹¶decodeTimeStampè®¾ä¸º kCMTimeInvalidã€‚
                                       è¡Œä¸ºä¸ç¡®å®šå¦‚æœåœ¨ä¸€ä¸ªæ ·å“CMSampleBufferï¼ˆæˆ–ç”šè‡³åœ¨åŒä¸€ä¸ªæµä¸­çš„å¤šä¸ªç¼“å†²å™¨ï¼‰å…·æœ‰ç›¸åŒçš„presentationTimeStampã€‚å¯ä»¥æ˜¯NULLã€‚
         *  @param sbufWithNewTiming   åœ¨è¾“å‡ºæ—¶ï¼ŒæŒ‡å‘çš„æ–°åˆ›å»ºçš„å‰¯ â€‹â€‹æœ¬CMSampleBuffer
         *
         *  @return ç»“æœç ã€‚è§ç»“æœä»£ç https://developer.apple.com/reference/coremedia/1669345-cmsamplebuffer#1670024
         */
        OSStatus err = CMSampleBufferCreateCopyWithNewTiming(kCFAllocatorDefault,
                                                             sampleBuffer,
                                                             1, // numSampleTimingEntries å…¥å£
                                                             &timingInfo,
                                                             &sbufWithNewTiming);
        
        // åˆ¤æ–­ä»å¦ä¸€ä¸ªæ ·å“ç¼“å†²ä½¿ç”¨æ–°çš„å®šæ—¶ä¿¡æ¯åˆ›å»ºä¸€ä¸ªCMSampleBufferã€‚æœ‰æ²¡æœ‰é”™è¯¯
        if (err) {
            LOG(@"CMSampleBufferCreateCopyWithNewTiming error");
            return;
        }
        
#pragma mark -- å¼€å§‹é‡‡æ ·
        // append the sample buffer if we can and increment presnetation time
        // å¦‚æœå¯ä»¥è¿½åŠ æ ·å“ç¼“å†²å’Œå¢é‡å‘ˆç°æ—¶é—´
        if ( [self.assetWriterInput isReadyForMoreMediaData] )
        {
            // è¿½åŠ SampleBuffer  sbufWithNewTimingåœ¨è¾“å‡ºæ—¶ï¼ŒæŒ‡å‘çš„æ–°åˆ›å»ºçš„å‰¯ â€‹â€‹æœ¬CMSampleBuffer
            if ([self.assetWriterInput appendSampleBuffer:sbufWithNewTiming])
            {
                self.nextPTS = CMTimeAdd(self.frameDuration, self.nextPTS);
                
                if ([[self imageFromSampleBuffer:sampleBuffer] isKindOfClass:[UIImage class]]) {
                    LOG(@"é‡‡é›†åˆ°å›¾åƒğŸ˜Š");
                }
            }
            else
            {
                NSError *error = [self.assetWriter error];
                LOG(@"failed to append sbuf: %@", error);
            }
        }
        else
        {
            ShowAlert(@"isReadyForMoreMediaData error");
        }
        
        // release the copy of the sample buffer we made
        CFRelease(sbufWithNewTiming);// å†™å…¥é‡‡æ ·åé‡Šæ”¾è¯¥å¯¹è±¡
        
        self.currentFrame++;
        
        dispatch_async(dispatch_get_main_queue(), ^{
            CGFloat p = (CGFloat)((CGFloat)self.currentFrame / (CGFloat)self.maxFrame);
            [self.progressBar setProgress:p animated:YES];
        });
        
        if (self.currentFrame >= self.maxFrame) {
            [self performSelectorOnMainThread:@selector(stopedForce) withObject:nil waitUntilDone:YES];
        }
    }
}
/**
 *  ä»åŸæ ·ç¼“å­˜ä¸­è·å–image
 *
 *  @param sampleBuffer æ•°æ®æº
 *
 *  @return iamge
 */
- (UIImage *)imageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer
{
    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
    // Lock the base address of the pixel buffer
    CVPixelBufferLockBaseAddress(imageBuffer,0);
    
    // Get the number of bytes per row for the pixel buffer
    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
    // Get the pixel buffer width and height
    size_t width = CVPixelBufferGetWidth(imageBuffer);
    size_t height = CVPixelBufferGetHeight(imageBuffer);
    
    // Create a device-dependent RGB color space
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    if (!colorSpace)
    {
        NSLog(@"CGColorSpaceCreateDeviceRGB failure");
        return nil;
    }
    
    // Get the base address of the pixel buffer
    void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);
    // Get the data size for contiguous planes of the pixel buffer.
    size_t bufferSize = CVPixelBufferGetDataSize(imageBuffer);
    
    // Create a Quartz direct-access data provider that uses data we supply
    CGDataProviderRef provider = CGDataProviderCreateWithData(NULL, baseAddress, bufferSize,
                                                              NULL);
    // Create a bitmap image from data supplied by our data provider
    CGImageRef cgImage =
    CGImageCreate(width,
                  height,
                  8,
                  32,
                  bytesPerRow,
                  colorSpace,
                  kCGImageAlphaNoneSkipFirst | kCGBitmapByteOrder32Little,
                  provider,
                  NULL,
                  true,
                  kCGRenderingIntentDefault);
    CGDataProviderRelease(provider);
    CGColorSpaceRelease(colorSpace);
    
    // Create and return an image object representing the specified Quartz image
    UIImage *image = [UIImage imageWithCGImage:cgImage];
    CGImageRelease(cgImage);
    
    CVPixelBufferUnlockBaseAddress(imageBuffer, 0);
    
    return image;
}

- (void)stopedForce
{
    [self stopRecordBtnClick:nil];
    ShowAlert(@"å½•åˆ¶å®Œæˆ");
}


#pragma mark - åˆå§‹åŒ–ä¸€äº›å‚æ•°

- (void)initPara {
    static int a = 0;
    a++;
    LOG(@"æˆ‘è¢«è°ƒç”¨äº†ï¼š%d",a);
    self.started = NO;
    self.currentFrame = 0;
    
#pragma mark -- è®¾ç½®å¸§ç‡ï¼Ÿ
    // 24 fps - taking 25 pictures will equal 1 second of video
    self.frameDuration = CMTimeMakeWithSeconds(1.0/20, 9000);

    self.maxFrame = 40*10; // è®¾ç½®æ¯ç§’24å¸–ï¼Œæœ€é•¿10ç§’
    
    [self.view bringSubviewToFront:_topBar];
    
    self.outputMovURL = [NSURL fileURLWithPath:[[self documentDir] stringByAppendingPathComponent:@"v.mov"]];
    self.outputMp4URL = [NSURL fileURLWithPath:[[self documentDir] stringByAppendingPathComponent:@"v.mp4"]];
}

#pragma mark - custom UI
#pragma mark -- åˆå§‹åŒ–ä¸€ä¸ªè¿›åº¦æ¡
/**
 *  åˆå§‹åŒ–ä¸€ä¸ªç²¾åº¦æ¡
 */
- (void)setupProgressBar
{
    self.progressBar = [[UIProgressView alloc] initWithProgressViewStyle:UIProgressViewStyleDefault];
    _progressBar.frame = CGRectMake(0.0f, 0.0f, kMainScreenWidth, 44.0f);
    [self.view addSubview:_progressBar];
}

#pragma mark - è§†å›¾æ§åˆ¶å™¨æ–¹æ³•

- (void)viewWillDisappear:(BOOL)animated {
    [super viewWillDisappear:animated];
    // å…³é—­ session
    if (_captureSession) [_captureSession stopRunning];
}

- (void)viewWillAppear:(BOOL)animated {
    [super viewWillAppear:animated];
    // å¼€å¯ session
    if (_captureSession) [_captureSession startRunning];
}

- (void)viewDidLoad {
    [super viewDidLoad];
    // Do any additional setup after loading the view.
    
    [self initPara];
    
    [self deleteFile:self.outputMovURL];
    
    [self deleteFile:self.outputMp4URL];
    
    [self setupProgressBar];
    
    [self setupAVCapture];
    
    
    
}

- (void)didReceiveMemoryWarning {
    [super didReceiveMemoryWarning];
    // Dispose of any resources that can be recreated.
}

#pragma mark - private method
/**
 *  è¿”å›ä¸€ä¸ªDocumentsè·¯å¾„
 *
 *  @return Documents
 */
- (NSString *)documentDir
{
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *docDir = nil;
    //    NSString *path = [NSHomeDirectory() stringByAppendingString:@""];
    if ([paths count] > 0) {
        docDir = [paths objectAtIndex:0];
    }
    return docDir;
}
/**
 *  åˆ é™¤è·¯å¾„ä¸‹çš„æ–‡ä»¶
 *
 *  @param filePath filePath
 */
- (void)deleteFile:(NSURL*)filePath
{
    NSFileManager *fm = [[NSFileManager alloc] init];
    // æ˜¯å¦å­˜åœ¨
    BOOL isExistsOk = [fm fileExistsAtPath:[filePath path]];
    
    if (isExistsOk) {
        [fm removeItemAtURL:filePath error:nil];
        LOG(@"file deleted:%@",filePath);
    } else {
        LOG(@"ğŸ file not exists:%@",filePath);
    }
}
/**
 *  è½¬åŒ–ä¸ºMP4
 */
- (void)convertToMp4
{
    NSString *_mp4Quality = AVAssetExportPresetMediumQuality;
    
    // è¯•å›¾åˆ é™¤åŸmp4
    [self deleteFile:self.outputMp4URL];
    
    // ç”Ÿæˆmp4
    /**
     *   è°ƒè¯•å‡½æ•°è€—æ—¶çš„åˆ©å™¨CFAbsoluteTimeGetCurrent
     *
     CFAbsoluteTime start = CFAbsoluteTimeGetCurrent();
     // do something
     CFAbsoluteTime end = CFAbsoluteTimeGetCurrent();
     NSLog(@"time cost: %0.3f", end - start);
     *
     */
    CFAbsoluteTime s = CFAbsoluteTimeGetCurrent();
    // åˆå§‹åŒ–è§†é¢‘åª’ä½“æ–‡ä»¶ ï¼ˆä½¿ç”¨å½•åˆ¶å¥½çš„Movæ–‡ä»¶ï¼‰
    AVURLAsset *avAsset = [AVURLAsset URLAssetWithURL:self.outputMovURL options:nil];
    // è¾“å‡ºé¢„è®¾ï¼ˆæ ‡å‡†æ ·å¼ï¼‰
    NSArray *compatiblePresets = [AVAssetExportSession exportPresetsCompatibleWithAsset:avAsset];
    // ä»è¿™ä¸ªæ•°ç»„ä¸­å–
    if ([compatiblePresets containsObject:_mp4Quality]) {
        // èµ„æºè¾“å‡ºä¼šè¯å±‚
        __block AVAssetExportSession *exportSession = [[AVAssetExportSession alloc]initWithAsset:avAsset presetName:_mp4Quality] ;
        // è¾“å‡ºè·¯å¾„
        exportSession.outputURL = self.outputMp4URL;
        //                exportSession.shouldOptimizeForNetworkUse = _networkOpt;
        // è¾“å‡ºæ–‡ä»¶æ ¼å¼
        exportSession.outputFileType = AVFileTypeMPEG4;
        // å¼‚æ­¥è¾“å‡º
        [exportSession exportAsynchronouslyWithCompletionHandler:^{
            // å¤„ç†å®Œæˆåèµ„æºè¾“å‡ºä¼šè¯å±‚çŠ¶æ€
            switch ([exportSession status]) {
                case AVAssetExportSessionStatusFailed:
                    LOG(@"AVAssetExportSessionStatusFailedï¼ˆå·²ç»å¤±è´¥ï¼‰:%@",[exportSession error]);
                    break;
                case AVAssetExportSessionStatusCancelled:
                    LOG(@"Export canceled å–æ¶ˆ");
                    break;
                case AVAssetExportSessionStatusCompleted:
                {
                    LOG(@"Successful! å®ŒæˆçŠ¶æ€");
                    [self performSelectorOnMainThread:@selector(convertFinish) withObject:nil waitUntilDone:NO];
                    CFAbsoluteTime e = CFAbsoluteTimeGetCurrent();
                    // è½¬åŒ–æ–‡ä»¶æ“ä½œæ¶ˆè€—çš„æ—¶é—´
                    LOG(@"è½¬åŒ–ä¸ºMP4æ–‡ä»¶æ“ä½œæ¶ˆè€—çš„æ—¶é—´ :%f",e-s);
                }
                    break;
                default:
                    break;
            }
        }];
    } else {
        ShowAlert(@"AVAsset doesn't support mp4 quality");
    }
}
/**
 *  è½¬åŒ–æ ¼å¼å®Œæˆ
 */
- (void)convertFinish
{
    ShowAlert(@"convert OK");
}
/**
 *  åœæ­¢å½•åˆ¶è§†é¢‘
 *
 *  @param sender åœæ­¢æŒ‰é’®
 */

#pragma mark - æ§åˆ¶æŒ‰é’®ç‚¹å‡»äº‹ä»¶

- (IBAction)backBtnClick:(UIBarButtonItem *)sender {
    [self dismissViewControllerAnimated:YES completion:nil];
    [self.navigationController popViewControllerAnimated:YES];
}

- (IBAction)playMovBtnClick:(UIBarButtonItem *)sender {
    NSFileManager *fm = [[NSFileManager alloc] init];
    // æ˜¯å¦å­˜åœ¨
    BOOL isExistsOk = [fm fileExistsAtPath:[_outputMovURL path]];
    
    if (isExistsOk) {
        MPMoviePlayController *vc = [[MPMoviePlayController alloc]init];
        vc.fileURLPath = _outputMovURL;
        [self presentViewController:vc animated:YES completion:nil];
    }
    else {
        ShowAlert(@"æ–‡ä»¶ä¸å­˜åœ¨");
    }
}

- (IBAction)playMp4BtnClick:(UIBarButtonItem *)sender {
    NSFileManager *fm = [[NSFileManager alloc] init];
    // æ˜¯å¦å­˜åœ¨
    BOOL isExistsOk = [fm fileExistsAtPath:[_outputMp4URL path]];
    
    if (isExistsOk) {
        MPMoviePlayController *vc = [[MPMoviePlayController alloc]init];
        vc.fileURLPath = _outputMp4URL;
        [self presentViewController:vc animated:YES completion:nil];
    }
    else {
        ShowAlert(@"æ–‡ä»¶ä¸å­˜åœ¨");
        // è½¬åŒ–ä¸ºMP4
        [self convertToMp4];
    }
}

- (IBAction)recordBtnClick:(UIBarButtonItem *)sender {
    if (self.started) {
        // æš‚åœ
        [sender setTitle:@"å¼€å§‹å½•åˆ¶"];
        self.started = NO;
    } else {
        // å¼€å§‹
        if (self.currentFrame == 0) {
            // è¯•å›¾åˆ ä¸€ä¸‹åŸèª©ä»¶
            [self deleteFile:_outputMovURL];
            [self deleteFile:_outputMp4URL];
        }
        [sender setTitle:@"æš‚åœå½•åˆ¶"];
        // å¼€å§‹å½•åˆ¶
        self.started = YES;
    }
}

- (IBAction)stopRecordBtnClick:(UIBarButtonItem *)sender {
    // æ ‡è®°ä¸ºåœæ­¢å½•åˆ¶è§†é¢‘
    _started = NO;
    if (_assetWriter != nil) {
        // è§†é¢‘å†™å…¥å£æ ‡è®°ä¸ºå·²å®Œæˆ
        [_assetWriterInput markAsFinished];
        //
        [_assetWriter finishWritingWithCompletionHandler:^{
            ;
        }];
        // é‡Šæ”¾è§†é¢‘å†™å…¥å£
        _assetWriterInput = nil;
        // é‡Šæ”¾æ–‡ä»¶å†™å…¥ç±»
        _assetWriter = nil;
    }
    _currentFrame = 0;
}

/*
#pragma mark - Navigation

// In a storyboard-based application, you will often want to do a little preparation before navigation
- (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender {
    // Get the new view controller using [segue destinationViewController].
    // Pass the selected object to the new view controller.
}

 
 
 
 
 
 
 
 
 2016-07-01 13:50:01.033 CustomMyCameraDemo01[796:185050] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.075 CustomMyCameraDemo01[796:185050] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.115 CustomMyCameraDemo01[796:185050] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.157 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.199 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.240 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.283 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.324 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.366 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.407 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.449 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.490 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.533 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.573 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.616 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.656 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.699 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.742 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.782 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.824 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.866 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.907 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.949 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 2016-07-01 13:50:01.991 CustomMyCameraDemo01[796:185051] AVCaptureVideoDataOutputSampleBufferDelegate è¢«è°ƒç”¨ ğŸ‘¿
 */

@end
